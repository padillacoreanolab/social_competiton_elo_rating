{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd97c972",
   "metadata": {},
   "source": [
    "# Reward Competition Elo rating Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0f58e4",
   "metadata": {},
   "source": [
    "## Importing other Python Libraries/Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf755b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import string\n",
    "import glob\n",
    "import ast\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c9bfe6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6770f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "# Getting the path of the root directory so that we can import repo specific functions\n",
    "git_repo_object = git.Repo('.', search_parent_directories=True)\n",
    "git_repo_directory = git_repo_object.working_tree_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3d2466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting path so that we can import functions\n",
    "sys.path.append(os.path.join(git_repo_directory, \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c74742",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.path.join(git_repo_directory, \"src\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104016aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elorating import calculation\n",
    "from elorating import dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea31ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase size of plot in jupyter\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (18,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7c1562",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018b9d08",
   "metadata": {},
   "source": [
    "- Experiment\n",
    "    - Observing competitve behavior between two mice inside an operant chamber where tone is associated with a single liquid food reward being dispensed. Mice are prompted to compete for access to the reward.\n",
    "- Data\n",
    "    - Excel spreadsheet of recorded reward comeptition results. The relevant columns are those of the \"Date\" of the recording, the ID's of the two competing subjects, and the results for each trial. Each row will be all the trials for this pair for the recording session.\n",
    "    - There are multiple cages for each sheet of the spreadsheet.\n",
    "- Purpose of this Jupyter Notebook\n",
    "    - To calculate the Elo rating of each mice after each interaction. The mice start off with an Elo rating of 1000. Elo ratings are calculated with the formula from here: https://www.omnicalculator.com/sports/elo . Then we will plot the change of Elo rating across all interactions. With the number of interactions on the X-Axis and the current Elo rating on the Y. There will be a line for mice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6944ae01",
   "metadata": {},
   "source": [
    "## Name of protocol for naming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa7153c",
   "metadata": {},
   "source": [
    "- This name will be used to name files and title plots. Please change if you are using a different protocol or adding more details\n",
    "    - **NOTE**: This should be changed based on the name the protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b74f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_name = \"reward_competition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d5b1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_name = \"rc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af647bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_name = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df447ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not cohort_name:\n",
    "    cohort_name = input(\"\"\"Type out the name of the cohort you are using. \n",
    "                        Make sure that this is typed as one word with individual words separated by underscore. i.e. pilot_3\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5269e1e",
   "metadata": {},
   "source": [
    "## Getting the file name of the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe8bdd3",
   "metadata": {},
   "source": [
    "- Default input folder and keyword to search the files for \n",
    "    - **NOTE**: This should not be changed unless there is a consistent change with the file naming convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b97a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = os.path.join(\".\", \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f07dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accomodates for both capitalization of the file names\n",
    "raw_data_file_keyword = '*[rR]eward*'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c077260f",
   "metadata": {},
   "source": [
    "# NOTE: If there is a set excel file used for this notebook, make the cell below into a code cell and put the path in the \"\" (quotation marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb949aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_file_path = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ea0990",
   "metadata": {},
   "source": [
    "- Asking the user what the path to the recording files are, with the option of using wildcards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906e10d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not raw_data_file_path:\n",
    "    raw_data_glob_pattern = input(\"\"\"Type out the path(address) of the raw behavioral recording excel sheets.\n",
    "    Remember that if you are using a relative path, it will be based off of the location of this Jupyter Notebook.\n",
    "\n",
    "    Globbing can also be used if you want to search with a wild card(Capitalization matters). \n",
    "    i.e. './data/*Home*' will be able to find './data/Homecage_observation.xlsx'\n",
    "\n",
    "    NOTE: If left blank, the path will automatically be guessed off of the default settings \n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964be5c0",
   "metadata": {},
   "source": [
    "- By default, this will search for files that are in the `./data` folder (in the folder that this notebook is in) that have key word you specified in the file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d963fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not raw_data_file_path:\n",
    "    # Using the user inputted path/pattern\n",
    "    if raw_data_glob_pattern.strip():\n",
    "        # Getting a list of all matching files\n",
    "        raw_data_files_list = glob.glob(raw_data_glob_pattern.strip(), recursive=True)\n",
    "        # Checking if there were any files that matched\n",
    "        if not raw_data_files_list:\n",
    "            raise ValueError(\"No files were found with the path/pattern of {}. Please rerun the previous cell with the correct path\".format(raw_data_glob_pattern))\n",
    "\n",
    "    # Using the default pattern\n",
    "    else:\n",
    "        raw_data_glob_pattern = os.path.join(input_folder, raw_data_file_keyword)\n",
    "        raw_data_files_list = glob.glob(raw_data_glob_pattern.strip(), recursive=True)\n",
    "        # Searching for matching files with recursion\n",
    "        if not raw_data_files_list:\n",
    "            raise ValueError(\"No files were found in {} that had the keyword {} in it\".format(input_folder, raw_data_file_keyword))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbd008a",
   "metadata": {},
   "source": [
    "- Checking to see if only one file is specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8c1417",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not raw_data_file_path:\n",
    "    if len(raw_data_files_list) >= 2:\n",
    "        raise ValueError(\"More than one file was found with the path/pattern of {}. Please rerun the previous cell with the correct path\".format(raw_data_glob_pattern))\n",
    "    else:\n",
    "        # Using the first(and only file) as the file path\n",
    "        raw_data_file_path = raw_data_files_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76129103",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539ffb33",
   "metadata": {},
   "source": [
    "## Getting a list of all the sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3ff67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the sheet names for the excel file\n",
    "xls = pd.ExcelFile(raw_data_file_path)\n",
    "raw_data_sheet_names = xls.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb563da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_data_sheet_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823f8e5e",
   "metadata": {},
   "source": [
    "# NOTE: If there is a set sheet names used for this notebook, edit the cell below with the name of the sheets each in quotation marks seperated by commas in the brackets\n",
    "   - i.e. `['CAGE 1', 'CAGE 2', 'CAGE 3', 'CAGE 4']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853bd6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputted_sheet_names_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e40c9d6",
   "metadata": {},
   "source": [
    "- Asking the user what sheets they want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c3aa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not inputted_sheet_names_list:\n",
    "    inputted_sheet_names_string = input(\"\"\"Type out the name of the sheets that you want to be processed. \n",
    "    Each name must be put in quotes and seperated by a comma(,). i.e. \"CAGE3\", \"CAGE4\"\n",
    "\n",
    "    The available sheets are: {}\n",
    "\n",
    "    Alternatively, you can use the index of the list of names above. \n",
    "    Remember, that Python is zero indexed so the first item will be have the 0 index, second the 1 index, and so on. \n",
    "    i.e. 1, 2\n",
    "\n",
    "    NOTE: If left blank, all sheets will be used\n",
    "    \"\"\".format(raw_data_sheet_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b1581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not inputted_sheet_names_list:\n",
    "    # Making a list out of the string of inputted sheet names\n",
    "    if inputted_sheet_names_string:\n",
    "        inputted_sheet_names_string = \"[\" + inputted_sheet_names_string + \"]\"\n",
    "        # Turning the string into a list\n",
    "        inputted_sheet_names_list = ast.literal_eval(inputted_sheet_names_string)\n",
    "    # Using all the sheet names if no sheet name is specified\n",
    "    else:\n",
    "        inputted_sheet_names_list =  raw_data_sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee3a658",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputted_sheet_names_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deda2bf",
   "metadata": {},
   "source": [
    "- Converting all the numbers into the sheet name that the index of the number corresponds to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bac1b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if inputted_sheet_names_list:\n",
    "    for index, sheet in enumerate(inputted_sheet_names_list):\n",
    "        # Checking if the sheet name was a number\n",
    "        if isinstance(sheet, int) and str(sheet).isdigit():\n",
    "            inputted_sheet_names_list[index] =  raw_data_sheet_names[sheet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdf26ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputted_sheet_names_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35a8c85",
   "metadata": {},
   "source": [
    "- Checking to see if all the sheets are in the excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caa55ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not set(inputted_sheet_names_list).issubset(raw_data_sheet_names):\n",
    "    # Getting all the sheets that were not in the original spreadsheet\n",
    "    not_included_sheet_names = set(inputted_sheet_names_list) - set(raw_data_sheet_names)\n",
    "    raise ValueError(\"All the listed sheet names are not in {}\".format(not_included_sheet_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a934ef8f",
   "metadata": {},
   "source": [
    "## Finding the row for the header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1c2300",
   "metadata": {},
   "source": [
    "- Headers are the row in a spreadsheet that has all the column names. Sometimes spreadsheets don't use the first row as the row with the column names. So, the row for the header will be asked or assumed to be the first row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70c4452",
   "metadata": {},
   "source": [
    "# NOTE: If there is a set row that has the column names, then enter the row number in the quotation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952c8063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the row number a string, so that \"0\" is treated as a True value\n",
    "all_header_row = \"0\"\n",
    "if not all_header_row:\n",
    "    all_header_row = False\n",
    "else:\n",
    "    all_header_row = int(all_header_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de68ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_name_to_everything = defaultdict(dict)\n",
    "for sheet in inputted_sheet_names_list:\n",
    "    if all_header_row is False:\n",
    "\n",
    "        print(\"\\nCurrent Sheet Name: {}\".format(sheet))    \n",
    "        per_sheet_dataframe = pd.read_excel(raw_data_file_path, sheet_name=sheet, header=0)\n",
    "\n",
    "        # Showing the columns that are chosen with the header being the 0th row\n",
    "        print(\"Columns Names: {}\".format(per_sheet_dataframe.columns))\n",
    "        # Show the dataframe that would be created with the header being the 0th row\n",
    "        print(\"First few rows of this dataframe:\")\n",
    "        print(pd.read_excel(raw_data_file_path, sheet_name=sheet, header=0).head())\n",
    "\n",
    "        # Allowing the user the choose the row number for the header\n",
    "        header_row = input(\"\"\"Type the row number to be used as the header\n",
    "        (AKA the row with the column name that you want to use.)\n",
    "        If you want to keep the column names that were displayed, type 0.\n",
    "        If you want to use a different row, then type the corresponding number. \n",
    "\n",
    "        The rows displayed in this cell are dataframes created from Pandas. \n",
    "        To use the row with the 0 index for column names, type 1. \n",
    "        For the row with the 1 index, it will be 2 and so on. i.e. 2\n",
    "\n",
    "        If you are looking at the original spread sheet, remember that Python is zero indexed. \n",
    "        So the first row will be 0, second will be 1, and so on. \n",
    "        i.e. 1\n",
    "\n",
    "        NOTE: If left blank, the original row that was used will be used.\n",
    "        \"\"\").strip()\n",
    "\n",
    "        if header_row == \"\":\n",
    "            header_row = 0\n",
    "        else:\n",
    "            header_row = int(header_row)\n",
    "    else:\n",
    "        header_row = all_header_row\n",
    "    \n",
    "    # Checking if any of the column names are from empty cells\n",
    "    column_names = \"\".join([str(col) for col in pd.read_excel(raw_data_file_path, sheet_name=sheet, header=header_row).columns])\n",
    "    # If a column name came from an empty cell, it would have \"Unnamed\" in it\n",
    "    if \"Unnamed\" in column_names:\n",
    "        raise ValueError(\"\"\"Not all the cells in the chosen row are filled in.\n",
    "                         Please choose a row that has the name of the columns\n",
    "                         \n",
    "                         The values in this row are: {}\"\"\".format(column_names))\n",
    "    else:\n",
    "        sheet_name_to_everything[sheet][\"header_row\"] = header_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5ea725",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_name_to_everything"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cc8630",
   "metadata": {},
   "source": [
    "## Reading in all the spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35a7cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going through each sheet and creating a dataframe of it\n",
    "for key, value in sheet_name_to_everything.items():\n",
    "    value[\"original_behavior_recording_dataframe\"] = pd.read_excel(raw_data_file_path, sheet_name=key, header=value[\"header_row\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dc8c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "value[\"original_behavior_recording_dataframe\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0c66f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "value[\"original_behavior_recording_dataframe\"].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15834e87",
   "metadata": {},
   "source": [
    "## Standarizing the Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7890d3",
   "metadata": {},
   "source": [
    "- Making all the column names lower case and removing any extra spaces in the beginning and at the end\n",
    "    - One dictionary per sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d5c711",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sheet_name_to_everything.items():\n",
    "    # Creating a dictionary that maps the original column name to the standarized one\n",
    "    column_name_to_standarized = defaultdict(dict)\n",
    "    for col in value[\"original_behavior_recording_dataframe\"]:\n",
    "        # Making the column name lower case and removing the spaces\n",
    "        column_name_to_standarized[col] = \"_\".join(str(col).lower().strip().split(\" \"))\n",
    "    value[\"column_name_to_standarized\"] = column_name_to_standarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e30c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "value[\"column_name_to_standarized\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fafcc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming all the columns to the lower case and space removed version\n",
    "for key, value in sheet_name_to_everything.items():\n",
    "    value[\"processed_behavior_recording_dataframe\"] = value[\"original_behavior_recording_dataframe\"].rename(columns=value[\"column_name_to_standarized\"])\n",
    "    value[\"processed_behavior_recording_dataframe\"][\"sheet_name\"] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49758e21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "value[\"processed_behavior_recording_dataframe\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_competition_df = sheet_name_to_everything[key][\"processed_behavior_recording_dataframe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e80a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_competition_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73e8b76",
   "metadata": {},
   "source": [
    "- Removing unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f7cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_competition_df = reward_competition_df.drop([col for col in reward_competition_df.columns if \"wins\" in col or \"ties\" in col], axis=1, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03065829",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [col for col in reward_competition_df.columns if \"time\" not in col.lower().strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dfd2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c796a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_competition_df = reward_competition_df[columns_to_keep].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae303843",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_competition_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678675bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_competition_df = reward_competition_df.dropna(subset=[\"trial_1_winner\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842d3520",
   "metadata": {},
   "source": [
    "## Add both IDs as a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b27e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_competition_df[\"animal_ids\"] = reward_competition_df[\"match\"].apply(lambda x: tuple(sorted([all_ids.strip() for all_ids in re.findall(r\"[-+]?(?:\\d*\\.\\d+|\\d+)\", x)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a2e030",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_competition_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46f05ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_competition_df[\"cohort\"] = cohort_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a3d0be",
   "metadata": {},
   "source": [
    "- Adding strain information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec020f6",
   "metadata": {},
   "source": [
    "# NOTE: If there are strains that are associated to each cage, then create a dictionary of cage numbers to strains inside the `{}`\n",
    "- i.e. `cage_to_strain = {\"1\": \"C57\", \"2\": \"C57\", \"3\": \"C57\", \"4\": \"CD1\", \"5\": \"CD1\", \"6\": \"CD1\"}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac1aa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cage_to_strain = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6893337",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_competition_df[\"strain\"] = reward_competition_df[\"cage\"].astype(str).map(cage_to_strain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0408a474",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cages = \"_\".join([str(cage) for cage in sorted(reward_competition_df[\"cage\"].unique())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb985e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a42738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "earliest_date = reward_competition_df[\"date\"].min()\n",
    "latest_date = reward_competition_df[\"date\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2bacdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "earliest_date = str(earliest_date.date()).replace(\"-\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce05a0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_date = str(latest_date.date()).replace(\"-\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e58f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "earliest_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2536a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274fb92d",
   "metadata": {},
   "source": [
    "- Creating a subfolder to put the Elo rating Spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d3f120",
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_rating_spreadsheet_output_directory = os.path.join(\".\", \"proc\", \"elo_rating_spread_sheets\", \"{}\".format(protocol_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db44537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_rating_spreadsheet_output_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3c5dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(elo_rating_spreadsheet_output_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e379ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"{}_{}_trial_as_columns_cages_{}_date_{}_{}.csv\".format(cohort_name, protocol_name, all_cages, earliest_date, latest_date).strip(\"_\")\n",
    "\n",
    "reward_competition_df.to_csv(os.path.join(elo_rating_spreadsheet_output_directory, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3484d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_competition_df = reward_competition_df.drop(columns=[\"sheet_name\", \"scorer\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a23e23",
   "metadata": {},
   "source": [
    "## Melt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93438071",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_competition_df[\"index\"] = reward_competition_df.index\n",
    "reward_competition_df = reward_competition_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5437ef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_competition_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4bd323",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_reward_competition_df = reward_competition_df.melt(id_vars=[\"index\", \"date\", \"cage\", \"box\", \"match\", \"animal_ids\"], \n",
    "        var_name=\"trial\", \n",
    "        value_name=\"winner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba1e8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_reward_competition_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35031b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_reward_competition_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4f9b17",
   "metadata": {},
   "source": [
    "- Dropping all rows that don't contain Winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0901cf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_reward_competition_df = melted_reward_competition_df.dropna(subset=\"winner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34906ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_reward_competition_df[\"winner\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23ca0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_reward_competition_df[\"keep_row\"] = melted_reward_competition_df[\"winner\"].apply(lambda x: True if \"tie\" in str(x).lower() or re.match(r'^-?\\d+(?:\\.\\d+)$', str(x)) else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0428a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_reward_competition_df = melted_reward_competition_df[melted_reward_competition_df[\"keep_row\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35473a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_reward_competition_df[\"winner\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1661cb6a",
   "metadata": {},
   "source": [
    "- Making all the ids into string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbd07a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_reward_competition_df[\"winner\"] = melted_reward_competition_df[\"winner\"].astype(str)\n",
    "melted_reward_competition_df[\"winner\"] = melted_reward_competition_df[\"winner\"].apply(lambda x: x.lower().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed390a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_reward_competition_df[\"animal_ids\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a088c99",
   "metadata": {},
   "source": [
    "- Making a different column for ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26a713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_reward_competition_df[\"match_is_tie\"] = melted_reward_competition_df[\"winner\"].apply(lambda x: True if \"tie\" in x.lower().strip() else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b1133c",
   "metadata": {},
   "source": [
    "- Replacing tie with the first animal id for elo score plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842a423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_reward_competition_df[\"winner\"] = melted_reward_competition_df.apply(lambda x: x[\"animal_ids\"][0] if x[\"match_is_tie\"] else x[\"winner\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc79a05c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "melted_reward_competition_df[melted_reward_competition_df[\"match_is_tie\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acccd98",
   "metadata": {},
   "source": [
    "- Dropping all rows that don't have trial in the name for the trial section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498f097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_reward_competition_df = melted_reward_competition_df[melted_reward_competition_df[\"trial\"].str.contains('trial')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b47cd30",
   "metadata": {},
   "source": [
    "- Getting the number of the trial so that we can order by number(instead of string, which would make 11 come before 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87155772",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_reward_competition_df[\"trial_number\"] = melted_reward_competition_df[\"trial\"].apply(lambda x: int(x.lower().strip(\"trial\").strip(\"winner\").strip(\"_\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00f352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_reward_competition_df = melted_reward_competition_df.sort_values([\"index\", \"trial_number\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad13471",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_reward_competition_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da34378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_reward_competition_df.head(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ac32dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_reward_competition_df[\"trial_number\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c411bb4",
   "metadata": {},
   "source": [
    "## Add a column for the loser ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a899a01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_reward_competition_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc18e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_reward_competition_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4cb336",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_reward_competition_df[\"loser\"] = melted_reward_competition_df.apply(lambda x: (list(set(x[\"animal_ids\"]) - set([x[\"winner\"]]))[0]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf33309",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_reward_competition_df[\"loser\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5cba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_reward_competition_df.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bef5093",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_reward_competition_df.tail(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a8cf50",
   "metadata": {},
   "source": [
    "## Adding the session number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b477728",
   "metadata": {},
   "source": [
    "- We are adding the session number to all the trials. The session number is counting the number of recording sessions that have happened up until that trial. Usually, each session in the spreadsheet is divided up by a session's first row having the date filled in. So we will label a new session when a date is filled in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f708c8a8",
   "metadata": {},
   "source": [
    "# Getting the Session number differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee5244c",
   "metadata": {},
   "source": [
    "- Getting the indexes of where each new session starts. So that we can add the session number to each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630e3faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_reward_competition_df[\"session_number_difference\"] = melted_reward_competition_df[\"date\"].astype('category').cat.codes.diff()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5a7871",
   "metadata": {},
   "source": [
    "## Calculating Elo rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a74ee77",
   "metadata": {},
   "source": [
    "- Example calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3bdd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculation.calculate_elo_rating(subject_elo_rating=1000, agent_elo_rating=2000, score=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf42d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculation.update_elo_rating(winner_id=\"A\", loser_id=\"B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317d3e5a",
   "metadata": {},
   "source": [
    "## Get the Elo rating for all the events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b955461",
   "metadata": {},
   "source": [
    "- Going through each row or interaction and calculating the new Elo rating for the winner and loser. This will create a new dataframe based off of the processed behavioral recording dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7df246",
   "metadata": {},
   "outputs": [],
   "source": [
    "cage_to_elo_rating_dict = defaultdict(dict)\n",
    "for cage in melted_reward_competition_df[\"cage\"].unique():\n",
    "    cage_df = melted_reward_competition_df[melted_reward_competition_df[\"cage\"] == cage]\n",
    "    cage_to_elo_rating_dict[cage] = calculation.iterate_elo_rating_calculation_for_dataframe(dataframe=cage_df, winner_id_column=\"winner\", loser_id_column=\"loser\", additional_columns=melted_reward_competition_df.columns, tie_column=\"match_is_tie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9955125",
   "metadata": {},
   "outputs": [],
   "source": [
    "cage_to_elo_rating_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b922f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cage_to_elo_rating_dict[list(cage_to_elo_rating_dict.keys())[0]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047631f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3246a34a",
   "metadata": {},
   "source": [
    "- Turning the dictionary into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defa2229",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cage_elo_rating_list = []\n",
    "for key in cage_to_elo_rating_dict.keys():\n",
    "    cage_elo_rating_df = pd.DataFrame.from_dict(cage_to_elo_rating_dict[key], orient=\"index\")\n",
    "    cage_elo_rating_df.insert(0, 'total_trial_number', range(0, 0 + len(cage_elo_rating_df)))\n",
    "    print(cage_elo_rating_df)\n",
    "    all_cage_elo_rating_list.append(cage_elo_rating_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c43bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cage_elo_rating_df = pd.concat(all_cage_elo_rating_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7241789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cage_elo_rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dffc2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cage_elo_rating_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd461bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cage_elo_rating_df[all_cage_elo_rating_df[\"match_is_tie\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9495e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cage_to_strain:\n",
    "    all_cage_elo_rating_df[\"strain\"] = all_cage_elo_rating_df[\"cage\"].astype(str).map(cage_to_strain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee1f96d",
   "metadata": {},
   "source": [
    "- Adding the cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a04d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cage_elo_rating_df[\"experiment_type\"] = protocol_name\n",
    "all_cage_elo_rating_df[\"cohort\"] = cohort_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b90334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cage_elo_rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44916516",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_cage_elo_rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aae0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a82ad050",
   "metadata": {},
   "source": [
    "## Saving the Elo Score Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d57cd7",
   "metadata": {},
   "source": [
    "- Create folders to save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9ec0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "228a864f",
   "metadata": {},
   "source": [
    "- Adding the cage information for each cage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0a08a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cage_elo_rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7557fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cage_elo_rating_df[all_cage_elo_rating_df[\"win_draw_loss\"] == 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9188487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f576750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_final_elo_rating_dict = defaultdict(dict)\n",
    "for index, subject_id in enumerate(sorted(all_cage_elo_rating_df[\"subject_id\"].unique())):\n",
    "    per_subject_df = all_cage_elo_rating_df[all_cage_elo_rating_df[\"subject_id\"] == subject_id]\n",
    "    id_to_final_elo_rating_dict[index][\"subject_id\"] = subject_id\n",
    "\n",
    "    id_to_final_elo_rating_dict[index][\"final_elo_rating\"] = per_subject_df.iloc[-1][\"updated_elo_rating\"]\n",
    "    id_to_final_elo_rating_dict[index][\"cohort\"] = per_subject_df.iloc[-1][\"cohort\"]\n",
    "    id_to_final_elo_rating_dict[index][\"cage\"] = per_subject_df.iloc[-1][\"cage\"]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c5c2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_final_elo_rating_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb7e43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_final_elo_rating_df = pd.DataFrame.from_dict(id_to_final_elo_rating_dict, orient=\"index\")\n",
    "# Adding protocol name\n",
    "id_to_final_elo_rating_df[\"experiment_type\"] = protocol_name\n",
    "# Adding rank\n",
    "id_to_final_elo_rating_df[\"rank\"] = id_to_final_elo_rating_df.groupby(\"cage\")[\"final_elo_rating\"].rank(\"dense\", ascending=False)\n",
    "# Sorting by cage and then id\n",
    "id_to_final_elo_rating_df = id_to_final_elo_rating_df.sort_values(by=['cage', \"subject_id\"], ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d45ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_final_elo_rating_df[\"rank\"] = id_to_final_elo_rating_df.groupby(\"cage\")[\"final_elo_rating\"].rank(\"dense\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f98789",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_final_elo_rating_df = id_to_final_elo_rating_df.sort_values(by=['cage', \"subject_id\"], ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec40c434",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_final_elo_rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbcc52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_final_elo_rating_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8c509a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b90df080",
   "metadata": {},
   "source": [
    "- Getting the cage numbersm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975b678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cages_list = []\n",
    "# Creating a list of all the cage numbers\n",
    "for key, value in sheet_name_to_everything.items():\n",
    "    try:\n",
    "        for cage in reward_competition_df[\"cage\"].unique():\n",
    "            all_cages_list.append(str(cage))\n",
    "    except:\n",
    "        print(\"WARNING: {} does not have cage number as columns\".format(key))\n",
    "        warnings.warn(\"Look at warning from above or below\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d2da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    all_cages_string = \"-\".join(sorted([sheet.lower().strip(\"cage\").strip() for sheet in all_cages_list]))\n",
    "    all_cages_string = \"cages-{}\".format(all_cages_string)\n",
    "    print(\"String of cage names to use for file name: {}\".format(all_cages_string))\n",
    "except: \n",
    "    warnings.warn(\"WARNING: There are no cage numbers to make a title out of\")\n",
    "    all_cages_string = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ab84e4",
   "metadata": {},
   "source": [
    "# Plotting the Elo Score by match number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691a8d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_output_directory = \"./proc/plots/reward_competition/cage_{}_date_{}_{}\".format(all_cages, earliest_date, latest_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d489f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_output_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c41a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(plot_output_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339a792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cage_elo_rating_df[\"subject_id\"] = all_cage_elo_rating_df[\"subject_id\"].astype(str)\n",
    "all_cage_elo_rating_df[\"agent_id\"] = all_cage_elo_rating_df[\"agent_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd7dd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase size of plot in jupyter\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (18,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ab80a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cage in all_cage_elo_rating_df[\"cage\"].unique():\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.rcParams[\"figure.figsize\"] = (18,10)\n",
    "    per_cage_df = all_cage_elo_rating_df[all_cage_elo_rating_df[\"cage\"] == cage]\n",
    "       \n",
    "    for index in per_cage_df[\"index\"].unique():\n",
    "        first_session_in_trial = per_cage_df[per_cage_df[\"index\"] == index].iloc[0][\"total_trial_number\"]\n",
    "        plt.vlines(x=[first_session_in_trial - 0.5], ymin=700, ymax=1300, colors='black', linestyle='dashed')\n",
    "\n",
    "    \n",
    "    \n",
    "    # Drawing a line for each subject\n",
    "    for subject in sorted(per_cage_df[\"subject_id\"].unique()):\n",
    "        # Getting all the rows with the current subject\n",
    "        subject_df = per_cage_df[per_cage_df[\"subject_id\"] == subject]\n",
    "        # Making the dates into days after the first session by subtracting all the dates by the first date\n",
    "        plt.plot(subject_df[\"total_trial_number\"], subject_df[\"updated_elo_rating\"], '-o', label=subject)\n",
    "    \n",
    "    # Labeling the X/Y Axis and the title\n",
    "    ax.set_xlabel(\"Trial Number\")\n",
    "    ax.set_ylabel(\"Elo Score\")\n",
    "    ax.set_title(\"{} Elo Score for {}: Cage {}\".format(\" \".join(cohort_name.split(\"_\")).capitalize(), string.capwords(\" \".join(protocol_name.split(\"_\"))), cage))\n",
    "    # To show the legend\n",
    "    ax.legend(loc=\"upper left\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylim(700, 1300) \n",
    "    file_name = \"{}_{}_elo_rating_{}_date_{}_{}.png\".format(cohort_name, protocol_name, cage, earliest_date, latest_date)\n",
    "    plt.savefig(os.path.join(plot_output_directory, file_name))  \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647efb8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a64fa57",
   "metadata": {},
   "source": [
    "# Saving the Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860a6a66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b194a6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_rating_spreadsheet_output_directory = os.path.join(\".\", \"proc\", \"elo_rating_spread_sheets\", \"{}\".format(protocol_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac69ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_rating_spreadsheet_output_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a36745",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(elo_rating_spreadsheet_output_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89038954",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_parts_separated = [cohort_name, all_cages_string, prefix_name, earliest_date, latest_date]\n",
    "file_name_parts_combined = \"_\".join([part for part in file_name_parts_separated if part])\n",
    "\n",
    "file_name_full = \"{}_elo-rating-history.csv\".format(file_name_parts_combined)\n",
    "print(file_name_full)\n",
    "all_cage_elo_rating_df.to_csv(os.path.join(elo_rating_spreadsheet_output_directory, file_name_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6fb663",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_full = \"{}_final-elo-rating.csv\".format(file_name_parts_combined)\n",
    "print(file_name_full)\n",
    "id_to_final_elo_rating_df.to_csv(os.path.join(elo_rating_spreadsheet_output_directory, file_name_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ab984d",
   "metadata": {},
   "source": [
    "## Seeing which subject is the dominant or submissive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276f6915",
   "metadata": {},
   "source": [
    "- Grouping all the rows with the same pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3f4900",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_processed_behavior_recording_df = melted_reward_competition_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3023295",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_processed_behavior_recording_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc046d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_processed_behavior_recording_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26368361",
   "metadata": {},
   "source": [
    "- Removing columns that would be unnecessary for the pairings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1a781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_processed_behavior_recording_df = all_processed_behavior_recording_df[['date', 'cage', 'match', 'animal_ids', 'trial', 'winner', 'match_is_tie', 'loser']]\n",
    "all_processed_behavior_recording_df['processed_cage_number'] = all_processed_behavior_recording_df['cage'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ae7bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_processed_behavior_recording_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1528dda1",
   "metadata": {},
   "source": [
    "- Adding a tie to the list of winners and losers if it's a tie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7809f1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_processed_behavior_recording_df[\"winner\"] = all_processed_behavior_recording_df.apply(lambda x: \"tie\" if x[\"match_is_tie\"] else x[\"winner\"], axis=1)\n",
    "all_processed_behavior_recording_df[\"loser\"] = all_processed_behavior_recording_df.apply(lambda x: \"tie\" if x[\"match_is_tie\"] else x[\"loser\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c759d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_processed_behavior_recording_df[all_processed_behavior_recording_df[\"match_is_tie\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb7d5c5",
   "metadata": {},
   "source": [
    "- Making a list of all the wins and loses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cc1595",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wins_per_pair = all_processed_behavior_recording_df.groupby([\"animal_ids\", \"date\"])['winner'].apply(list)\n",
    "all_loses_per_pair = all_processed_behavior_recording_df.groupby([\"animal_ids\", \"date\"])['loser'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5782e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_competition_per_pair_df = pd.concat([all_wins_per_pair, all_loses_per_pair], axis=1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5728c70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_competition_per_pair_df = all_competition_per_pair_df.rename(columns={k: \"rc_\" + k for k in all_competition_per_pair_df.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593df90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_competition_per_pair_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bac283",
   "metadata": {},
   "source": [
    "- Seeing how often the winners or losers change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f8fff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all the ties\n",
    "all_competition_per_pair_df[\"rc_winner_no_ties\"] = all_competition_per_pair_df.apply(lambda row: [x for x in row[\"rc_winner\"] if x in row[\"rc_animal_ids\"]], axis=1)\n",
    "all_competition_per_pair_df[\"rc_loser_no_ties\"] = all_competition_per_pair_df.apply(lambda row: [x for x in row[\"rc_loser\"] if x in row[\"rc_animal_ids\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a1d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the each item with the item after it to see if they are the same of not\n",
    "all_competition_per_pair_df[\"rc_different_result_as_previous\"] = all_competition_per_pair_df[\"rc_winner_no_ties\"].apply(lambda x: [True if left != right else False for (left, right) in zip(x[1:], x[:-1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bfc0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_competition_per_pair_df[\"rc_number_of_switches\"] = all_competition_per_pair_df[\"rc_different_result_as_previous\"].apply(lambda x: sum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afbc172",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_competition_per_pair_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb43019",
   "metadata": {},
   "source": [
    "# NOTE: This assumes that Ties aren't the most common outcome for a given pair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785591cd",
   "metadata": {},
   "source": [
    "## Aggregate all the wins/loses across reward competition sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a28d40",
   "metadata": {},
   "source": [
    "- Getting the average number of switches between winner and loser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16f6de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming column to not be confused with previous version\n",
    "average_switches_per_pair_df = all_competition_per_pair_df.groupby('rc_animal_ids').mean().rename({'rc_number_of_switches': 'rc_average_number_of_switches'}, axis=1)  # new method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcf7e61",
   "metadata": {},
   "source": [
    "- Combining all the trials into one list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0a4eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_per_pair_df = pd.concat([all_competition_per_pair_df.groupby('rc_animal_ids')['rc_winner'].apply(list), all_competition_per_pair_df.groupby('rc_animal_ids')['rc_loser'].apply(list)], axis=1)\n",
    "all_sessions_per_pair_df = pd.concat([all_sessions_per_pair_df, average_switches_per_pair_df], axis=1)\n",
    "all_sessions_per_pair_df = all_sessions_per_pair_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c40ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_per_pair_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d439365",
   "metadata": {},
   "source": [
    "- Flattening the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a49940",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_per_pair_df[\"rc_winner\"] = all_sessions_per_pair_df[\"rc_winner\"].apply(lambda x: [element for innerList in x for element in innerList])\n",
    "all_sessions_per_pair_df[\"rc_loser\"] = all_sessions_per_pair_df[\"rc_loser\"].apply(lambda x: [element for innerList in x for element in innerList])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d85410",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_per_pair_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97201539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c38f7ad",
   "metadata": {},
   "source": [
    "- Calculating overall winner and loser based on who has the most wins/loses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16119d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all the ties\n",
    "all_sessions_per_pair_df[\"rc_winner_no_ties\"] = all_sessions_per_pair_df.apply(lambda row: [x for x in row[\"rc_winner\"] if x in row[\"rc_animal_ids\"]], axis=1)\n",
    "all_sessions_per_pair_df[\"rc_loser_no_ties\"] = all_sessions_per_pair_df.apply(lambda row: [x for x in row[\"rc_loser\"] if x in row[\"rc_animal_ids\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a1e9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting the first ID for the winner and second for the loser if there is equal number of wins and loses \n",
    "all_sessions_per_pair_df[\"rc_averaged_winner\"] = all_sessions_per_pair_df.apply(lambda x: Counter(x[\"rc_winner_no_ties\"]).most_common(1)[0][0] if x[\"rc_winner_no_ties\"].count(Counter(x[\"rc_winner_no_ties\"]).most_common(1)[0][1]) != len(x[\"rc_winner_no_ties\"]) / 2 else x[\"rc_animal_ids\"][0], axis=1)\n",
    "all_sessions_per_pair_df[\"rc_averaged_loser\"] = all_sessions_per_pair_df.apply(lambda x: Counter(x[\"rc_loser_no_ties\"]).most_common(1)[0][0] if x[\"rc_loser_no_ties\"].count(Counter(x[\"rc_loser_no_ties\"]).most_common(1)[0][1]) != len(x[\"rc_winner_no_ties\"]) / 2 else x[\"rc_animal_ids\"][1], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eda858c",
   "metadata": {},
   "source": [
    "- Checking to see if any of the IDs are the same or are ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28147d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_per_pair_df[\"rc_averaged_loser\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d44a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_per_pair_df[\"rc_averaged_winner\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c42b0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_per_pair_df[all_sessions_per_pair_df[\"rc_averaged_loser\"] == all_sessions_per_pair_df[\"rc_averaged_winner\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9c7cb4",
   "metadata": {},
   "source": [
    "- Counting the number of wins and loses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9677258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_per_pair_df[\"rc_winner_count\"] = all_sessions_per_pair_df.apply(lambda x: x[\"rc_winner\"].count(x[\"rc_averaged_winner\"]), axis=1)\n",
    "all_sessions_per_pair_df[\"rc_loser_count\"] = all_sessions_per_pair_df.apply(lambda x: x[\"rc_winner\"].count(x[\"rc_averaged_loser\"]), axis=1)\n",
    "all_sessions_per_pair_df[\"rc_tie_count\"] = all_sessions_per_pair_df.apply(lambda x: x[\"rc_winner\"].count(\"tie\"), axis=1)\n",
    "all_sessions_per_pair_df[\"rc_all_match_count_including_ties\"] = all_sessions_per_pair_df[\"rc_winner\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e1470c",
   "metadata": {},
   "source": [
    "- Comparing the number of wins vs loses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c7f08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_per_pair_df[\"rc_winner_count_minus_loser_count\"] = all_sessions_per_pair_df[\"rc_winner_count\"] - all_sessions_per_pair_df[\"rc_loser_count\"]\n",
    "# winner number / (winner + loser number with no ties)\n",
    "all_sessions_per_pair_df[\"rc_win_to_win_plus_lost_ratio\"] = all_sessions_per_pair_df.apply(lambda x: x[\"rc_winner_count\"] / len(x[\"rc_winner_no_ties\"]), axis=1)\n",
    "# winner number / (winner + loser + tie)\n",
    "all_sessions_per_pair_df[\"rc_win_to_all_ratio\"] = all_sessions_per_pair_df.apply(lambda x: x[\"rc_winner_count\"] / x[\"rc_all_match_count_including_ties\"], axis=1)\n",
    "# all_sessions_per_pair_df[\"rc_is_win_to_all_ratio_tie\"] = all_sessions_per_pair_df[\"rc_win_to_all_ratio\"].apply(lambda x: True if x < 0.5 else False)\n",
    "all_sessions_per_pair_df[\"rc_is_win_to_win_and_loss_ratio_tie\"] = all_sessions_per_pair_df[\"rc_win_to_win_plus_lost_ratio\"].apply(lambda x: True if x < 0.6 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0736d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_per_pair_df[\"rc_is_win_to_win_and_loss_ratio_tie\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1164eed7",
   "metadata": {},
   "source": [
    "- Comparing the number of ties to the number of matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b630c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_per_pair_df[\"rc_tie_to_all_ratio\"] = all_sessions_per_pair_df.apply(lambda x: x[\"rc_tie_count\"] / x[\"rc_all_match_count_including_ties\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac306c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_per_pair_df[~all_sessions_per_pair_df[\"rc_is_win_to_win_and_loss_ratio_tie\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef6fede",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_per_pair_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fcbed2",
   "metadata": {},
   "source": [
    "- Checking to see if there are any pairs with more than two sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba360cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_per_pair_df[all_sessions_per_pair_df[\"rc_all_match_count_including_ties\"] > 40]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dc8ef3",
   "metadata": {},
   "source": [
    "- Adding the cage information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc7a1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_cuplicate_all_processed_behavior_recording_df = all_processed_behavior_recording_df[[\"animal_ids\", \"processed_cage_number\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f66af3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dropped_cuplicate_all_processed_behavior_recording_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20dd3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_to_cage = pd.Series(dropped_cuplicate_all_processed_behavior_recording_df[\"processed_cage_number\"].values, index=dropped_cuplicate_all_processed_behavior_recording_df[\"animal_ids\"]).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ff51c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_to_cage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7098c946",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_per_pair_df[\"processed_cage_number\"] = all_sessions_per_pair_df[\"rc_animal_ids\"].map(pair_to_cage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0b91ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_per_pair_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b8bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_per_pair_df[\"cohort\"] = cohort_name\n",
    "all_sessions_per_pair_df[\"processed_cage_number\"] = all_sessions_per_pair_df[\"processed_cage_number\"].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d4089",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_per_pair_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95369da",
   "metadata": {},
   "source": [
    "- Verifying if all the stats are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3fe2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_per_pair_df[\"rc_winner\"][0].count(all_sessions_per_pair_df[\"rc_animal_ids\"][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f929c517",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_per_pair_df[\"rc_winner\"][0].count(all_sessions_per_pair_df[\"rc_animal_ids\"][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_per_pair_df[\"rc_winner\"][0].count(\"tie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556a1979",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_sessions_per_pair_df[\"rc_winner\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee30281",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_sessions_per_pair_df[\"rc_winner_no_ties\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdbb401",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_per_pair_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad23428",
   "metadata": {},
   "source": [
    "# Getting the number of wins per winner and loser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee17117",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_competition_per_pair_df[\"cohort\"] = cohort_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bde3f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_competition_per_pair_df[\"processed_cage_number\"] = all_competition_per_pair_df[\"rc_animal_ids\"].map(pair_to_cage).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea77b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_competition_per_pair_df[\"strain\"] = all_competition_per_pair_df[\"processed_cage_number\"].map(cage_to_strain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4702a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_competition_per_pair_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57135c10",
   "metadata": {},
   "source": [
    "- Calculating overall winner and loser based on who has the most wins/loses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c64a3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all the ties\n",
    "all_competition_per_pair_df[\"rc_winner_no_ties\"] = all_competition_per_pair_df.apply(lambda row: [x for x in row[\"rc_winner\"] if x in row[\"rc_animal_ids\"]], axis=1)\n",
    "all_competition_per_pair_df[\"rc_loser_no_ties\"] = all_competition_per_pair_df.apply(lambda row: [x for x in row[\"rc_loser\"] if x in row[\"rc_animal_ids\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134cec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting the first ID for the winner and second for the loser if there is equal number of wins and loses \n",
    "all_competition_per_pair_df[\"rc_averaged_winner\"] = all_competition_per_pair_df.apply(lambda x: Counter(x[\"rc_winner_no_ties\"]).most_common(1)[0][0] if x[\"rc_winner_no_ties\"].count(Counter(x[\"rc_winner_no_ties\"]).most_common(1)[0][1]) != len(x[\"rc_winner_no_ties\"]) / 2 else x[\"rc_animal_ids\"][0], axis=1)\n",
    "all_competition_per_pair_df[\"rc_averaged_loser\"] = all_competition_per_pair_df.apply(lambda x: Counter(x[\"rc_loser_no_ties\"]).most_common(1)[0][0] if x[\"rc_loser_no_ties\"].count(Counter(x[\"rc_loser_no_ties\"]).most_common(1)[0][1]) != len(x[\"rc_winner_no_ties\"]) / 2 else x[\"rc_animal_ids\"][1], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58355a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(all_competition_per_pair_df[\"rc_winner_no_ties\"][0]).most_common(1)[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e1abf2",
   "metadata": {},
   "source": [
    "- Checking to see if any of the IDs are the same or are ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123ea54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_competition_per_pair_df[\"rc_averaged_loser\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0138063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_competition_per_pair_df[\"rc_averaged_winner\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59e1c83",
   "metadata": {},
   "source": [
    "- Counting the number of wins and loses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680437bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_competition_per_pair_df[\"rc_winner_count\"] = all_competition_per_pair_df.apply(lambda x: x[\"rc_winner\"].count(x[\"rc_averaged_winner\"]), axis=1)\n",
    "all_competition_per_pair_df[\"rc_loser_count\"] = all_competition_per_pair_df.apply(lambda x: x[\"rc_winner\"].count(x[\"rc_averaged_loser\"]), axis=1)\n",
    "all_competition_per_pair_df[\"rc_tie_count\"] = all_competition_per_pair_df.apply(lambda x: x[\"rc_winner\"].count(\"tie\"), axis=1)\n",
    "all_competition_per_pair_df[\"rc_all_match_count_including_ties\"] = all_competition_per_pair_df[\"rc_winner\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc2445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_competition_per_pair_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971d507c",
   "metadata": {},
   "source": [
    "- Comparing the number of wins vs loses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88261a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_competition_per_pair_df[\"rc_winner_count_minus_loser_count\"] = all_competition_per_pair_df[\"rc_winner_count\"] - all_competition_per_pair_df[\"rc_loser_count\"]\n",
    "# winner number / (winner + loser number with no ties)\n",
    "all_competition_per_pair_df[\"rc_win_to_win_plus_lost_ratio\"] = all_competition_per_pair_df.apply(lambda x: x[\"rc_winner_count\"] / len(x[\"rc_winner_no_ties\"]), axis=1)\n",
    "# winner number / (winner + loser + tie)\n",
    "all_competition_per_pair_df[\"rc_win_to_all_ratio\"] = all_competition_per_pair_df.apply(lambda x: x[\"rc_winner_count\"] / x[\"rc_all_match_count_including_ties\"], axis=1)\n",
    "all_competition_per_pair_df[\"rc_is_win_to_win_and_loss_ratio_tie\"] = all_competition_per_pair_df[\"rc_win_to_win_plus_lost_ratio\"].apply(lambda x: True if x < 0.6 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a124e3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_competition_per_pair_df[\"rc_is_win_to_win_and_loss_ratio_tie\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6c8567",
   "metadata": {},
   "source": [
    "- Comparing the number of ties to the number of matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931ca959",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_competition_per_pair_df[\"rc_tie_to_all_ratio\"] = all_competition_per_pair_df.apply(lambda x: x[\"rc_tie_count\"] / x[\"rc_all_match_count_including_ties\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd25a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_competition_per_pair_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05acf94b",
   "metadata": {},
   "source": [
    "- Saving the competition dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740d35fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"{}_{}_grouped_by_pairs_cage_{}_date_{}_{}.csv\".format(cohort_name, protocol_name, all_cages, earliest_date, latest_date).strip(\"_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3805229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_rating_spreadsheet_output_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccf275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85c57b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"{}_{}_all_competition_cage_{}_date_{}_{}.csv\".format(cohort_name, protocol_name, all_cages, earliest_date, latest_date).strip(\"_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6345968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_rating_spreadsheet_output_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2176f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecc835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_competition_per_pair_df.to_csv(os.path.join(elo_rating_spreadsheet_output_directory, file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58819113",
   "metadata": {},
   "source": [
    "# Saving the spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f579fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"{}_{}_grouped_by_pairs_cage_{}_date_{}_{}.csv\".format(cohort_name, prefix_name, all_cages_string, earliest_date, latest_date).strip(\"_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21dfa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_rating_spreadsheet_output_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e22186b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfile_name\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'file_name' is not defined"
     ]
    }
   ],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccddec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions_per_pair_df.to_csv(os.path.join(elo_rating_spreadsheet_output_directory, file_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "3f8ee54d6a5e4a8880ade41546e056b482b8e637dc064f40b470e6968242c2bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
